{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyank96/idl-spring-22-project-deepar/blob/main/DL_project_basic_model_all_data_no_vol_with_context_shreya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gaDREnRqYtJ",
        "outputId": "7f0e3ad4-fa04-4099-8d82-30a042dd57c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'idl-spring-22-project-deepar' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/priyank96/idl-spring-22-project-deepar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3-iTN4vqhby"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCce3iObql8A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import logging\n",
        "from sklearn import preprocessing\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCTfJxrHqqd_"
      },
      "outputs": [],
      "source": [
        "!python3 /content/idl-spring-22-project-deepar/src/data/company_data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJLrLqhpqzLA"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "DATA_PATH = '/content/idl-spring-22-project-deepar/data'\n",
        "\n",
        "with open(DATA_PATH+'/index_to_company.pkl','rb') as f:\n",
        "  index_to_company = pickle.load(f)\n",
        "\n",
        "with open(DATA_PATH+'/company_to_index.pkl','rb') as f:\n",
        "  company_to_index = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_3Hv4K3rEbW",
        "outputId": "628278cb-7fc1-44e3-8c21-f3eb2fdbdff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'FCX', 1: 'FTCH', 2: 'TGT', 3: 'CRWD', 4: 'CRON', 5: 'MGM', 6: 'CRSM', 7: 'PRU', 8: 'CLOV', 9: 'BTCUSD', 10: 'NEM', 11: 'FXE', 12: 'VRM', 13: 'TER', 14: 'WCLD', 15: 'AVCT', 16: 'GOLD', 17: 'NICH', 18: 'MMM', 19: 'VUZI', 20: 'LMND', 21: 'AMGN', 22: 'CCIV', 23: 'CBAT', 24: 'APT', 25: 'LUV', 26: 'QYLD', 27: 'SYK', 28: 'LPTX', 29: 'AA', 30: 'CFG', 31: 'JDST', 32: 'BLUE', 33: 'AEO', 34: 'YHOO', 35: 'SOXX', 36: 'OIH', 37: 'NIO', 38: 'NXPI', 39: 'GGG', 40: 'UPS', 41: 'SBGI', 42: 'WFC', 43: 'FAMI', 44: 'CVNA', 45: 'DIS', 46: 'MAG', 47: 'E', 48: 'ETRM', 49: 'CRTX', 50: 'GOOS', 51: 'XERS', 52: 'HPE', 53: 'BYND', 54: 'ARKK', 55: 'DLTR', 56: 'CS', 57: 'PAR', 58: 'SHAK', 59: 'KWEB', 60: 'GM', 61: 'RCRT', 62: 'CL', 63: 'SOS', 64: 'LOCO', 65: 'VZ', 66: 'IMCC', 67: 'XNET', 68: 'ZGNX', 69: 'CNY', 70: 'G', 71: 'MCMJ', 72: 'EVO', 73: 'DB', 74: 'LC', 75: 'CLPT', 76: 'GWSO', 77: 'DOCU', 78: 'TWLO', 79: 'NET', 80: 'A', 81: 'HLT', 82: 'ALDX', 83: 'SOFI', 84: 'INPX', 85: 'PINS', 86: 'DIA', 87: 'HOG', 88: 'KAP', 89: 'TLRY', 90: 'SHOP', 91: 'LTC', 92: 'UA', 93: 'NTRB', 94: 'XOP', 95: 'SI', 96: 'SAFE', 97: 'EWZ', 98: 'CVS', 99: 'XLB', 100: 'XBI', 101: 'ENPH', 102: 'XME', 103: 'TRIP', 104: 'TTCM', 105: 'ISRG', 106: 'ACFN', 107: 'AUPH', 108: 'NTAP', 109: 'WDAY', 110: 'CCJ', 111: 'ATVK', 112: 'GT', 113: 'ACI', 114: 'AFMD', 115: 'PPSI', 116: 'MS', 117: 'HYG', 118: 'CHWY', 119: 'L', 120: 'ATVI', 121: 'AG', 122: 'BTCS', 123: 'RKUNY', 124: 'CLX', 125: 'VXRT', 126: 'JNK', 127: 'EBAY', 128: 'NKLA', 129: 'AMBA', 130: 'MO', 131: 'FUTU', 132: 'TWTR', 133: 'CVE', 134: 'CNQ', 135: 'DPZ', 136: 'BNTX', 137: 'BABL', 138: 'KRE', 139: 'TIME', 140: 'ABUS', 141: 'ABNB', 142: 'NCNO', 143: 'PCLN', 144: 'HGEN', 145: 'APA', 146: 'CODX', 147: 'EXEL', 148: 'YRCW', 149: 'XHB', 150: 'GE', 151: 'PXD', 152: 'FIZZ', 153: 'RVPH', 154: 'PULM', 155: 'TZA', 156: 'LAZR', 157: 'SBET', 158: 'NK', 159: 'PIXY', 160: 'SRNE', 161: 'BTU', 162: 'JPM', 163: 'XAIR', 164: 'BX', 165: 'FSLY', 166: 'SYPR', 167: 'LK', 168: 'XSPA', 169: 'EXAS', 170: 'OPRA', 171: 'XLE', 172: 'SONY', 173: 'JOBY', 174: 'ASTR', 175: 'SMH', 176: 'VALE', 177: 'WM', 178: 'BBIO', 179: 'UAVS', 180: 'UAL', 181: 'CAR', 182: 'TTWO', 183: 'AMD', 184: 'BBBY', 185: 'MDB', 186: 'EA', 187: 'PLTR', 188: 'IDEX', 189: 'UBER', 190: 'AVGO', 191: 'IBM', 192: 'ATOM', 193: 'PTON', 194: 'INO', 195: 'DAX', 196: 'LULU', 197: 'PLUG', 198: 'HUM', 199: 'MGI', 200: 'GNOG', 201: 'QS', 202: 'PEP', 203: 'FANG', 204: 'ACAD', 205: 'AMZN', 206: 'ATUS', 207: 'MA', 208: 'SOTK', 209: 'DKS', 210: 'SFIX', 211: 'NRT', 212: 'LABD', 213: 'GWPH', 214: 'AUD', 215: 'GDX', 216: 'GRIN', 217: 'CYDY', 218: 'SPCE', 219: 'IVZ', 220: 'PG', 221: 'ANET', 222: 'YALA', 223: 'CNGT', 224: 'BLK', 225: 'GLSI', 226: 'Z', 227: 'LIT', 228: 'BMY', 229: 'USD', 230: 'EVGO', 231: 'SDRL', 232: 'RCL', 233: 'INTC', 234: 'VBIV', 235: 'BA', 236: 'MRVL', 237: 'IVST', 238: 'ASO', 239: 'SXTC', 240: 'DIG', 241: 'PACB', 242: 'SOLR', 243: 'CDXC', 244: 'ASAN', 245: 'RSX', 246: 'XELA', 247: 'MJN', 248: 'AR', 249: 'CROX', 250: 'XRT', 251: 'NVAX', 252: 'AMT', 253: 'TQQQ', 254: 'OPTT', 255: 'DVAX', 256: 'VXX', 257: 'CNK', 258: 'RICK', 259: 'AZ', 260: 'PLD', 261: 'ENS', 262: 'X', 263: 'AEHR', 264: 'DM', 265: 'ETHUSD', 266: 'DISCA', 267: 'BABA', 268: 'TQLB', 269: 'MSFT', 270: 'GNCA', 271: 'R', 272: 'FB', 273: 'GMVD', 274: 'MYOV', 275: 'YNDX', 276: 'CABO', 277: 'HUBS', 278: 'BB', 279: 'DNN', 280: 'SOL', 281: 'MSTR', 282: 'TSCO', 283: 'SECI', 284: 'OXY', 285: 'OIL', 286: 'SNOW', 287: 'ANY', 288: 'ALPP', 289: 'GILD', 290: 'URA', 291: 'CHGG', 292: 'BAC', 293: 'MRK', 294: 'W', 295: 'LOVE', 296: 'IPOOF', 297: 'FOLD', 298: 'GEVO', 299: 'LCID', 300: 'HAIN', 301: 'TRCH', 302: 'RIOT', 303: 'USO', 304: 'SDC', 305: 'F', 306: 'ENZC', 307: 'OSTK', 308: 'JMIA', 309: 'B', 310: 'RGBPP', 311: 'AMAT', 312: 'PLBY', 313: 'QQQ', 314: 'WGO', 315: 'TRI', 316: 'AU', 317: 'INFY', 318: 'XLU', 319: 'QCOM', 320: 'CEI', 321: 'PNC', 322: 'ILMN', 323: 'ATIP', 324: 'LGIH', 325: 'XPEV', 326: 'PSTV', 327: 'GPS', 328: 'OPEN', 329: 'APPS', 330: 'FUBO', 331: 'SNDL', 332: 'CRDL', 333: 'WKHS', 334: 'MU', 335: 'SPLK', 336: 'PLAN', 337: 'FAST', 338: 'FTNT', 339: 'CF', 340: 'FSR', 341: 'NUGT', 342: 'BBY', 343: 'FND', 344: 'LOTZ', 345: 'AMRS', 346: 'NG', 347: 'AMC', 348: 'STLA', 349: 'POLA', 350: 'EQT', 351: 'CRKR', 352: 'GBTC', 353: 'WISH', 354: 'NOK', 355: 'SVXY', 356: 'UCTT', 357: 'BLNK', 358: 'DAL', 359: 'GTBIF', 360: 'SCHW', 361: 'SKLZ', 362: 'DSE', 363: 'GTE', 364: 'FXS', 365: 'DDOG', 366: 'KSS', 367: 'PSFE', 368: 'MLCO', 369: 'TNDM', 370: 'UVXY', 371: 'TSM', 372: 'PZZA', 373: 'PROG', 374: 'HNT', 375: 'SNAP', 376: 'NXTP', 377: 'FSLR', 378: 'UNH', 379: 'GGAL', 380: 'NKTR', 381: 'BEEM', 382: 'KBE', 383: 'COTY', 384: 'NEAR', 385: 'VFF', 386: 'CHRA', 387: 'VTXB', 388: 'VMNT', 389: 'VVOS', 390: 'ET', 391: 'DE', 392: 'FCEL', 393: 'RAD', 394: 'NKE', 395: 'IWO', 396: 'ABBV', 397: 'LVS', 398: 'UPST', 399: 'URBN', 400: 'EXK', 401: 'PGR', 402: 'ARWR', 403: 'ULTA', 404: 'NEGG', 405: 'GRIL', 406: 'TLT', 407: 'AEZS', 408: 'UST', 409: 'NURO', 410: 'URNM', 411: 'MP', 412: 'CELG', 413: 'J', 414: 'WYNN', 415: 'GRPN', 416: 'M', 417: 'SPOT', 418: 'CTXS', 419: 'KMI', 420: 'SQQQ', 421: 'VTVT', 422: 'GNRC', 423: 'CRV', 424: 'IFXY', 425: 'YETI', 426: 'AMKR', 427: 'IBB', 428: 'BRN', 429: 'BKNG', 430: 'GLD', 431: 'GOOGL', 432: 'SBUX', 433: 'JUNO', 434: 'BP', 435: 'DKNG', 436: 'BFLY', 437: 'XLK', 438: 'SLV', 439: 'CSCO', 440: 'GLW', 441: 'XOM', 442: 'ITUS', 443: 'ALXN', 444: 'ETSY', 445: 'HUYA', 446: 'CPRI', 447: 'ASML', 448: 'RIG', 449: 'SDY', 450: 'RUN', 451: 'HCC', 452: 'MMAT', 453: 'KO', 454: 'ZS', 455: 'FDX', 456: 'FBRX', 457: 'MTUM', 458: 'GOGO', 459: 'NTDOY', 460: 'HES', 461: 'SWKS', 462: 'CNBS', 463: 'U', 464: 'K', 465: 'ENJ', 466: 'VET', 467: 'MRNA', 468: 'WLL', 469: 'JD', 470: 'PANW', 471: 'JNUG', 472: 'SEAH', 473: 'SRPT', 474: 'MINM', 475: 'BTT', 476: 'UMAX', 477: 'AJRD', 478: 'PHUN', 479: 'CRM', 480: 'EMN', 481: 'EEM', 482: 'SLB', 483: 'CC', 484: 'MSOS', 485: 'NWBO', 486: 'SOLO', 487: 'GP', 488: 'OPAD', 489: 'PCG', 490: 'OCGN', 491: 'XGTI', 492: 'DGLY', 493: 'ZNGA', 494: 'UNG', 495: 'NFLX', 496: 'OKTA', 497: 'MVIS', 498: 'JBHT', 499: 'CMPS', 500: 'VIAC', 501: 'DASH', 502: 'CLDX', 503: 'DDS', 504: 'DVN', 505: 'FXI', 506: 'AHT', 507: 'ADBE', 508: 'PYPL', 509: 'KBH', 510: 'COPX', 511: 'ERBB', 512: 'RWB', 513: 'OEG', 514: 'ORCL', 515: 'LMT', 516: 'EXAC', 517: 'FREE', 518: 'JEF', 519: 'AVLR', 520: 'AMRN', 521: 'AMP', 522: 'TKAT', 523: 'LQMT', 524: 'COST', 525: 'MTN', 526: 'GPRO', 527: 'NVDA', 528: 'NQ', 529: 'CMG', 530: 'QURE', 531: 'IRTC', 532: 'PSLV', 533: 'KSM', 534: 'ROKU', 535: 'XLP', 536: 'CCL', 537: 'CAMT', 538: 'HIMX', 539: 'MNST', 540: 'LRCX', 541: 'IBKR', 542: 'TECK', 543: 'T', 544: 'CPSH', 545: 'RWBYF', 546: 'BIIB', 547: 'SNPW', 548: 'CAT', 549: 'INMD', 550: 'GME', 551: 'TYL', 552: 'DELL', 553: 'TDOC', 554: 'ARCB', 555: 'CDNA', 556: 'NAK', 557: 'SBEV', 558: 'SAVA', 559: 'MOS', 560: 'UNP', 561: 'GPN', 562: 'HAS', 563: 'CMRX', 564: 'MELI', 565: 'GS', 566: 'D', 567: 'CLSK', 568: 'LEN', 569: 'HZNP', 570: 'LRDR', 571: 'ABT', 572: 'APRN', 573: 'XLF', 574: 'WTI', 575: 'SKIN', 576: 'LNKD', 577: 'SONO', 578: 'PAVM', 579: 'CGC', 580: 'ELYS', 581: 'LUNA', 582: 'BTBT', 583: 'IWM', 584: 'SE', 585: 'PENN', 586: 'RIO', 587: 'BILL', 588: 'LVGO', 589: 'NEWR', 590: 'AUNXF', 591: 'BHP', 592: 'CLF', 593: 'ALK', 594: 'WORK', 595: 'SPRT', 596: 'TXN', 597: 'LAC', 598: 'ASM', 599: 'SQ', 600: 'JNJ', 601: 'ES', 602: 'GRWG', 603: 'VLO', 604: 'DOGZ', 605: 'ATER', 606: 'LABU', 607: 'XXII', 608: 'NTLA', 609: 'LTRY', 610: 'RDFN', 611: 'RKT', 612: 'MSTO', 613: 'TVIX', 614: 'ORGN', 615: 'GSK', 616: 'IGV', 617: 'BHVN', 618: 'EXPE', 619: 'PFE', 620: 'XLV', 621: 'ZI', 622: 'MARA', 623: 'CVX', 624: 'NTNX', 625: 'SEAC', 626: 'WWR', 627: 'GOEV', 628: 'KC', 629: 'SANT', 630: 'IPA', 631: 'TTD', 632: 'ONE', 633: 'C', 634: 'AGQ', 635: 'MCD', 636: 'MRIN', 637: 'HD', 638: 'V', 639: 'ISIG', 640: 'GOOG', 641: 'NGCG', 642: 'PDD', 643: 'AGR', 644: 'ACN', 645: 'BIDU', 646: 'STMP', 647: 'GERN', 648: 'RH', 649: 'AAL', 650: 'CELH', 651: 'SGC', 652: 'STX', 653: 'AI', 654: 'PSTH', 655: 'RELI', 656: 'SENS', 657: 'WMT', 658: 'LINK', 659: 'RENN', 660: 'BBIG', 661: 'ZM', 662: 'SAVE', 663: 'BKKT', 664: 'P', 665: 'DBA', 666: 'UEC', 667: 'TRVN'}\n",
            "{'FCX': 0, 'FTCH': 1, 'TGT': 2, 'CRWD': 3, 'CRON': 4, 'MGM': 5, 'CRSM': 6, 'PRU': 7, 'CLOV': 8, 'BTCUSD': 9, 'NEM': 10, 'FXE': 11, 'VRM': 12, 'TER': 13, 'WCLD': 14, 'AVCT': 15, 'GOLD': 16, 'NICH': 17, 'MMM': 18, 'VUZI': 19, 'LMND': 20, 'AMGN': 21, 'CCIV': 22, 'CBAT': 23, 'APT': 24, 'LUV': 25, 'QYLD': 26, 'SYK': 27, 'LPTX': 28, 'AA': 29, 'CFG': 30, 'JDST': 31, 'BLUE': 32, 'AEO': 33, 'YHOO': 34, 'SOXX': 35, 'OIH': 36, 'NIO': 37, 'NXPI': 38, 'GGG': 39, 'UPS': 40, 'SBGI': 41, 'WFC': 42, 'FAMI': 43, 'CVNA': 44, 'DIS': 45, 'MAG': 46, 'E': 47, 'ETRM': 48, 'CRTX': 49, 'GOOS': 50, 'XERS': 51, 'HPE': 52, 'BYND': 53, 'ARKK': 54, 'DLTR': 55, 'CS': 56, 'PAR': 57, 'SHAK': 58, 'KWEB': 59, 'GM': 60, 'RCRT': 61, 'CL': 62, 'SOS': 63, 'LOCO': 64, 'VZ': 65, 'IMCC': 66, 'XNET': 67, 'ZGNX': 68, 'CNY': 69, 'G': 70, 'MCMJ': 71, 'EVO': 72, 'DB': 73, 'LC': 74, 'CLPT': 75, 'GWSO': 76, 'DOCU': 77, 'TWLO': 78, 'NET': 79, 'A': 80, 'HLT': 81, 'ALDX': 82, 'SOFI': 83, 'INPX': 84, 'PINS': 85, 'DIA': 86, 'HOG': 87, 'KAP': 88, 'TLRY': 89, 'SHOP': 90, 'LTC': 91, 'UA': 92, 'NTRB': 93, 'XOP': 94, 'SI': 95, 'SAFE': 96, 'EWZ': 97, 'CVS': 98, 'XLB': 99, 'XBI': 100, 'ENPH': 101, 'XME': 102, 'TRIP': 103, 'TTCM': 104, 'ISRG': 105, 'ACFN': 106, 'AUPH': 107, 'NTAP': 108, 'WDAY': 109, 'CCJ': 110, 'ATVK': 111, 'GT': 112, 'ACI': 113, 'AFMD': 114, 'PPSI': 115, 'MS': 116, 'HYG': 117, 'CHWY': 118, 'L': 119, 'ATVI': 120, 'AG': 121, 'BTCS': 122, 'RKUNY': 123, 'CLX': 124, 'VXRT': 125, 'JNK': 126, 'EBAY': 127, 'NKLA': 128, 'AMBA': 129, 'MO': 130, 'FUTU': 131, 'TWTR': 132, 'CVE': 133, 'CNQ': 134, 'DPZ': 135, 'BNTX': 136, 'BABL': 137, 'KRE': 138, 'TIME': 139, 'ABUS': 140, 'ABNB': 141, 'NCNO': 142, 'PCLN': 143, 'HGEN': 144, 'APA': 145, 'CODX': 146, 'EXEL': 147, 'YRCW': 148, 'XHB': 149, 'GE': 150, 'PXD': 151, 'FIZZ': 152, 'RVPH': 153, 'PULM': 154, 'TZA': 155, 'LAZR': 156, 'SBET': 157, 'NK': 158, 'PIXY': 159, 'SRNE': 160, 'BTU': 161, 'JPM': 162, 'XAIR': 163, 'BX': 164, 'FSLY': 165, 'SYPR': 166, 'LK': 167, 'XSPA': 168, 'EXAS': 169, 'OPRA': 170, 'XLE': 171, 'SONY': 172, 'JOBY': 173, 'ASTR': 174, 'SMH': 175, 'VALE': 176, 'WM': 177, 'BBIO': 178, 'UAVS': 179, 'UAL': 180, 'CAR': 181, 'TTWO': 182, 'AMD': 183, 'BBBY': 184, 'MDB': 185, 'EA': 186, 'PLTR': 187, 'IDEX': 188, 'UBER': 189, 'AVGO': 190, 'IBM': 191, 'ATOM': 192, 'PTON': 193, 'INO': 194, 'DAX': 195, 'LULU': 196, 'PLUG': 197, 'HUM': 198, 'MGI': 199, 'GNOG': 200, 'QS': 201, 'PEP': 202, 'FANG': 203, 'ACAD': 204, 'AMZN': 205, 'ATUS': 206, 'MA': 207, 'SOTK': 208, 'DKS': 209, 'SFIX': 210, 'NRT': 211, 'LABD': 212, 'GWPH': 213, 'AUD': 214, 'GDX': 215, 'GRIN': 216, 'CYDY': 217, 'SPCE': 218, 'IVZ': 219, 'PG': 220, 'ANET': 221, 'YALA': 222, 'CNGT': 223, 'BLK': 224, 'GLSI': 225, 'Z': 226, 'LIT': 227, 'BMY': 228, 'USD': 229, 'EVGO': 230, 'SDRL': 231, 'RCL': 232, 'INTC': 233, 'VBIV': 234, 'BA': 235, 'MRVL': 236, 'IVST': 237, 'ASO': 238, 'SXTC': 239, 'DIG': 240, 'PACB': 241, 'SOLR': 242, 'CDXC': 243, 'ASAN': 244, 'RSX': 245, 'XELA': 246, 'MJN': 247, 'AR': 248, 'CROX': 249, 'XRT': 250, 'NVAX': 251, 'AMT': 252, 'TQQQ': 253, 'OPTT': 254, 'DVAX': 255, 'VXX': 256, 'CNK': 257, 'RICK': 258, 'AZ': 259, 'PLD': 260, 'ENS': 261, 'X': 262, 'AEHR': 263, 'DM': 264, 'ETHUSD': 265, 'DISCA': 266, 'BABA': 267, 'TQLB': 268, 'MSFT': 269, 'GNCA': 270, 'R': 271, 'FB': 272, 'GMVD': 273, 'MYOV': 274, 'YNDX': 275, 'CABO': 276, 'HUBS': 277, 'BB': 278, 'DNN': 279, 'SOL': 280, 'MSTR': 281, 'TSCO': 282, 'SECI': 283, 'OXY': 284, 'OIL': 285, 'SNOW': 286, 'ANY': 287, 'ALPP': 288, 'GILD': 289, 'URA': 290, 'CHGG': 291, 'BAC': 292, 'MRK': 293, 'W': 294, 'LOVE': 295, 'IPOOF': 296, 'FOLD': 297, 'GEVO': 298, 'LCID': 299, 'HAIN': 300, 'TRCH': 301, 'RIOT': 302, 'USO': 303, 'SDC': 304, 'F': 305, 'ENZC': 306, 'OSTK': 307, 'JMIA': 308, 'B': 309, 'RGBPP': 310, 'AMAT': 311, 'PLBY': 312, 'QQQ': 313, 'WGO': 314, 'TRI': 315, 'AU': 316, 'INFY': 317, 'XLU': 318, 'QCOM': 319, 'CEI': 320, 'PNC': 321, 'ILMN': 322, 'ATIP': 323, 'LGIH': 324, 'XPEV': 325, 'PSTV': 326, 'GPS': 327, 'OPEN': 328, 'APPS': 329, 'FUBO': 330, 'SNDL': 331, 'CRDL': 332, 'WKHS': 333, 'MU': 334, 'SPLK': 335, 'PLAN': 336, 'FAST': 337, 'FTNT': 338, 'CF': 339, 'FSR': 340, 'NUGT': 341, 'BBY': 342, 'FND': 343, 'LOTZ': 344, 'AMRS': 345, 'NG': 346, 'AMC': 347, 'STLA': 348, 'POLA': 349, 'EQT': 350, 'CRKR': 351, 'GBTC': 352, 'WISH': 353, 'NOK': 354, 'SVXY': 355, 'UCTT': 356, 'BLNK': 357, 'DAL': 358, 'GTBIF': 359, 'SCHW': 360, 'SKLZ': 361, 'DSE': 362, 'GTE': 363, 'FXS': 364, 'DDOG': 365, 'KSS': 366, 'PSFE': 367, 'MLCO': 368, 'TNDM': 369, 'UVXY': 370, 'TSM': 371, 'PZZA': 372, 'PROG': 373, 'HNT': 374, 'SNAP': 375, 'NXTP': 376, 'FSLR': 377, 'UNH': 378, 'GGAL': 379, 'NKTR': 380, 'BEEM': 381, 'KBE': 382, 'COTY': 383, 'NEAR': 384, 'VFF': 385, 'CHRA': 386, 'VTXB': 387, 'VMNT': 388, 'VVOS': 389, 'ET': 390, 'DE': 391, 'FCEL': 392, 'RAD': 393, 'NKE': 394, 'IWO': 395, 'ABBV': 396, 'LVS': 397, 'UPST': 398, 'URBN': 399, 'EXK': 400, 'PGR': 401, 'ARWR': 402, 'ULTA': 403, 'NEGG': 404, 'GRIL': 405, 'TLT': 406, 'AEZS': 407, 'UST': 408, 'NURO': 409, 'URNM': 410, 'MP': 411, 'CELG': 412, 'J': 413, 'WYNN': 414, 'GRPN': 415, 'M': 416, 'SPOT': 417, 'CTXS': 418, 'KMI': 419, 'SQQQ': 420, 'VTVT': 421, 'GNRC': 422, 'CRV': 423, 'IFXY': 424, 'YETI': 425, 'AMKR': 426, 'IBB': 427, 'BRN': 428, 'BKNG': 429, 'GLD': 430, 'GOOGL': 431, 'SBUX': 432, 'JUNO': 433, 'BP': 434, 'DKNG': 435, 'BFLY': 436, 'XLK': 437, 'SLV': 438, 'CSCO': 439, 'GLW': 440, 'XOM': 441, 'ITUS': 442, 'ALXN': 443, 'ETSY': 444, 'HUYA': 445, 'CPRI': 446, 'ASML': 447, 'RIG': 448, 'SDY': 449, 'RUN': 450, 'HCC': 451, 'MMAT': 452, 'KO': 453, 'ZS': 454, 'FDX': 455, 'FBRX': 456, 'MTUM': 457, 'GOGO': 458, 'NTDOY': 459, 'HES': 460, 'SWKS': 461, 'CNBS': 462, 'U': 463, 'K': 464, 'ENJ': 465, 'VET': 466, 'MRNA': 467, 'WLL': 468, 'JD': 469, 'PANW': 470, 'JNUG': 471, 'SEAH': 472, 'SRPT': 473, 'MINM': 474, 'BTT': 475, 'UMAX': 476, 'AJRD': 477, 'PHUN': 478, 'CRM': 479, 'EMN': 480, 'EEM': 481, 'SLB': 482, 'CC': 483, 'MSOS': 484, 'NWBO': 485, 'SOLO': 486, 'GP': 487, 'OPAD': 488, 'PCG': 489, 'OCGN': 490, 'XGTI': 491, 'DGLY': 492, 'ZNGA': 493, 'UNG': 494, 'NFLX': 495, 'OKTA': 496, 'MVIS': 497, 'JBHT': 498, 'CMPS': 499, 'VIAC': 500, 'DASH': 501, 'CLDX': 502, 'DDS': 503, 'DVN': 504, 'FXI': 505, 'AHT': 506, 'ADBE': 507, 'PYPL': 508, 'KBH': 509, 'COPX': 510, 'ERBB': 511, 'RWB': 512, 'OEG': 513, 'ORCL': 514, 'LMT': 515, 'EXAC': 516, 'FREE': 517, 'JEF': 518, 'AVLR': 519, 'AMRN': 520, 'AMP': 521, 'TKAT': 522, 'LQMT': 523, 'COST': 524, 'MTN': 525, 'GPRO': 526, 'NVDA': 527, 'NQ': 528, 'CMG': 529, 'QURE': 530, 'IRTC': 531, 'PSLV': 532, 'KSM': 533, 'ROKU': 534, 'XLP': 535, 'CCL': 536, 'CAMT': 537, 'HIMX': 538, 'MNST': 539, 'LRCX': 540, 'IBKR': 541, 'TECK': 542, 'T': 543, 'CPSH': 544, 'RWBYF': 545, 'BIIB': 546, 'SNPW': 547, 'CAT': 548, 'INMD': 549, 'GME': 550, 'TYL': 551, 'DELL': 552, 'TDOC': 553, 'ARCB': 554, 'CDNA': 555, 'NAK': 556, 'SBEV': 557, 'SAVA': 558, 'MOS': 559, 'UNP': 560, 'GPN': 561, 'HAS': 562, 'CMRX': 563, 'MELI': 564, 'GS': 565, 'D': 566, 'CLSK': 567, 'LEN': 568, 'HZNP': 569, 'LRDR': 570, 'ABT': 571, 'APRN': 572, 'XLF': 573, 'WTI': 574, 'SKIN': 575, 'LNKD': 576, 'SONO': 577, 'PAVM': 578, 'CGC': 579, 'ELYS': 580, 'LUNA': 581, 'BTBT': 582, 'IWM': 583, 'SE': 584, 'PENN': 585, 'RIO': 586, 'BILL': 587, 'LVGO': 588, 'NEWR': 589, 'AUNXF': 590, 'BHP': 591, 'CLF': 592, 'ALK': 593, 'WORK': 594, 'SPRT': 595, 'TXN': 596, 'LAC': 597, 'ASM': 598, 'SQ': 599, 'JNJ': 600, 'ES': 601, 'GRWG': 602, 'VLO': 603, 'DOGZ': 604, 'ATER': 605, 'LABU': 606, 'XXII': 607, 'NTLA': 608, 'LTRY': 609, 'RDFN': 610, 'RKT': 611, 'MSTO': 612, 'TVIX': 613, 'ORGN': 614, 'GSK': 615, 'IGV': 616, 'BHVN': 617, 'EXPE': 618, 'PFE': 619, 'XLV': 620, 'ZI': 621, 'MARA': 622, 'CVX': 623, 'NTNX': 624, 'SEAC': 625, 'WWR': 626, 'GOEV': 627, 'KC': 628, 'SANT': 629, 'IPA': 630, 'TTD': 631, 'ONE': 632, 'C': 633, 'AGQ': 634, 'MCD': 635, 'MRIN': 636, 'HD': 637, 'V': 638, 'ISIG': 639, 'GOOG': 640, 'NGCG': 641, 'PDD': 642, 'AGR': 643, 'ACN': 644, 'BIDU': 645, 'STMP': 646, 'GERN': 647, 'RH': 648, 'AAL': 649, 'CELH': 650, 'SGC': 651, 'STX': 652, 'AI': 653, 'PSTH': 654, 'RELI': 655, 'SENS': 656, 'WMT': 657, 'LINK': 658, 'RENN': 659, 'BBIG': 660, 'ZM': 661, 'SAVE': 662, 'BKKT': 663, 'P': 664, 'DBA': 665, 'UEC': 666, 'TRVN': 667}\n"
          ]
        }
      ],
      "source": [
        "print(index_to_company)\n",
        "print(company_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnbO60IvrI2o"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = '/content/idl-spring-22-project-deepar/data'\n",
        "\n",
        "stock_inputs = np.load(DATA_PATH + '/stock_inputs.npy', allow_pickle=True)\n",
        "stock_labels = np.load(DATA_PATH + '/stock_labels.npy', allow_pickle=True)\n",
        "\n",
        "stock_test_inputs = np.load(DATA_PATH + '/stock_test_inputs.npy',allow_pickle=True)\n",
        "stock_test_labels = np.load(DATA_PATH + '/stock_test_labels.npy',allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flp9MfWcrMGR"
      },
      "outputs": [],
      "source": [
        "NUM_TRAIN_SAMPLES = 500000\n",
        "NUM_TEST_SAMPLES  = 100000\n",
        "\n",
        "stock_inputs_trimmed = stock_inputs[:NUM_TRAIN_SAMPLES,:,:]\n",
        "stock_labels_trimmed = stock_labels[:NUM_TRAIN_SAMPLES,:]\n",
        "\n",
        "stock_test_inputs_trimmed = stock_test_inputs[:NUM_TEST_SAMPLES,:,:]\n",
        "stock_test_labels_trimmed = stock_test_labels[:NUM_TEST_SAMPLES,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxAJ9HCBrTYV",
        "outputId": "3418da5a-f4f0-445f-ca98-497e504e2e1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "stock_inputs_trimmed shape (500000, 192, 5)\n",
            "stock_labels_trimmed shape (500000, 192)\n",
            "stock_test_inputs_trimmed shape (100000, 192, 5)\n",
            "stock_test_labels_trimmed shape (100000, 192)\n"
          ]
        }
      ],
      "source": [
        "print('stock_inputs_trimmed shape', stock_inputs_trimmed.shape)\n",
        "print('stock_labels_trimmed shape', stock_labels_trimmed.shape)\n",
        "print('stock_test_inputs_trimmed shape', stock_test_inputs_trimmed.shape)\n",
        "print('stock_test_labels_trimmed shape', stock_test_labels_trimmed.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNsUZLNYrVxq"
      },
      "outputs": [],
      "source": [
        "# On the Filtered input, check the number of actual companies retained\n",
        "\n",
        "train_comp_ids = set()\n",
        "test_comp_ids  = set()\n",
        "\n",
        "# Every Seq in the window will belong to the same company\n",
        "# Hence seq_id = 0\n",
        "# cov_id = -1 (last index)\n",
        "seq_id = 0\n",
        "cov_id = -1\n",
        "\n",
        "for sample in range(0, NUM_TRAIN_SAMPLES):\n",
        "  train_comp_ids.add(stock_inputs_trimmed[sample][seq_id][cov_id])\n",
        "\n",
        "for sample in range(0, NUM_TEST_SAMPLES):\n",
        "  test_comp_ids.add(stock_test_inputs_trimmed[sample][seq_id][cov_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ytWKpsVrYJ3",
        "outputId": "226c918a-84f1-451e-a400-e5306f109c1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0]\n",
            "249\n",
            "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 9.0, 10.0, 11.0, 13.0, 15.0, 16.0, 18.0, 19.0, 21.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 67.0, 68.0, 69.0, 70.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 80.0, 81.0, 82.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0]\n",
            "123\n"
          ]
        }
      ],
      "source": [
        "print(sorted(train_comp_ids))\n",
        "print(len(train_comp_ids))\n",
        "print(sorted(test_comp_ids))\n",
        "print(len(test_comp_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO-hil0-raWQ",
        "outputId": "6d3594a6-fe3e-4a09-bd73-b04689b80b9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_classes': 249, 'embedding_dim': 128, 'cov_dim': 3, 'lstm_hidden_dim': 256, 'lstm_layers': 4, 'window_size': 192, 'batch_size': 32, 'learning_rate': 0.002, 'epochs': 100, 'num_test_samples': 100000, 'num_train_samples': 500000, 'conditioning_period': 168, 'prediction_period': 24, 'context_length': 10}\n"
          ]
        }
      ],
      "source": [
        "params = {\n",
        "    'num_classes': len(train_comp_ids),\n",
        "    'embedding_dim':128,\n",
        "    'cov_dim': 3,\n",
        "    'lstm_hidden_dim': 256,\n",
        "    'lstm_layers':4 ,\n",
        "    'window_size':192,\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 2e-3,\n",
        "    'epochs':100,\n",
        "    'num_test_samples': NUM_TEST_SAMPLES,\n",
        "    'num_train_samples': NUM_TRAIN_SAMPLES,\n",
        "    'conditioning_period': 168,\n",
        "    'prediction_period': 24,\n",
        "    'context_length':10\n",
        "}\n",
        "\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMQ1gz6sring"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, Sampler\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "DATA_PATH = '/content/idl-spring-22-project-deepar/data'\n",
        "\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.data = stock_inputs_trimmed\n",
        "        #Delete Volume\n",
        "        self.data = np.delete(self.data, 1, axis=2)\n",
        "        self.label = stock_labels_trimmed\n",
        "        self.train_len = self.data.shape[0]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.train_len\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        x1 = torch.from_numpy(self.data[index].astype(np.float32))\n",
        "        x2 = torch.from_numpy(self.label[index].astype(np.float32))\n",
        "        return x1, x2  \n",
        "    \n",
        "    def collate_fn(self, batch):\n",
        "      batch_x,batch_y = [],[]\n",
        "      for x,y in batch:\n",
        "        # print(\"x shape \",x.shape)\n",
        "        opening_price = x[:,0].unsqueeze(1)\n",
        "        open_prev = torch.zeros_like(opening_price)\n",
        "        for i in range(1,params['context_length']):\n",
        "          open_prev = torch.zeros_like(opening_price)\n",
        "          open_prev[i:,:] = opening_price[:-i,:]\n",
        "          x = torch.cat((x[:,:i],open_prev,x[:,i:]),dim=1)\n",
        "        batch_x.append(x)\n",
        "        batch_y.append(y)\n",
        "      return torch.stack(batch_x),torch.stack(batch_y)\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.data = stock_test_inputs_trimmed\n",
        "        #Delete Volume\n",
        "        self.data = np.delete(self.data, 1, axis=2)\n",
        "        self.label = stock_test_labels_trimmed\n",
        "        self.test_len = self.data.shape[0]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.test_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      x1 = torch.from_numpy(self.data[index].astype(np.float32))\n",
        "      x2 = torch.from_numpy(self.label[index].astype(np.float32))\n",
        "      return x1, x2\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "      batch_x,batch_y = [],[]\n",
        "      for x,y in batch:\n",
        "        # print(\"x shape \",x.shape)\n",
        "        opening_price = x[:,0].unsqueeze(1)\n",
        "        open_prev = torch.zeros_like(opening_price)\n",
        "        for i in range(1,params['context_length']):\n",
        "          open_prev = torch.zeros_like(opening_price)\n",
        "          open_prev[i:,:] = opening_price[:-i,:]\n",
        "          x = torch.cat((x[:,:i],open_prev,x[:,i:]),dim=1)\n",
        "        batch_x.append(x)\n",
        "        batch_y.append(y)\n",
        "      return torch.stack(batch_x),torch.stack(batch_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTWDVazXr4Uw"
      },
      "outputs": [],
      "source": [
        "train_data = TrainDataset()\n",
        "test_data  = TestDataset()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=params['batch_size'], shuffle=True, collate_fn = train_data.collate_fn)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=params['batch_size'], shuffle=False, collate_fn = test_data.collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukf0jKF1tA7R"
      },
      "outputs": [],
      "source": [
        "# Sanity Check - Plot Windows\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "def plot_output_windowed(company_data, window_id):\n",
        "  # 1st index is output (prediction)\n",
        "  x=np.linspace(1, len(company_data[window_id][1]), num=len(company_data[window_id][1]))\n",
        "  fig = px.line(x=x, y=company_data[window_id][1])\n",
        "  fig.show()\n",
        "  print(\"op\", company_data[window_id][1])\n",
        "\n",
        "def plot_input_covariate_windowed(company_data, window_id, covariate_index):\n",
        "  # 0th index is input (the covariates)\n",
        "  x=np.linspace(1, company_data[window_id][0].shape[0], num=len(company_data[window_id][0][:,covariate_index]))\n",
        "  fig = px.line(x=x, y=company_data[window_id][0][:,covariate_index])\n",
        "  fig.show()\n",
        "  print(\"ip\", company_data[window_id][0][:,covariate_index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hdW1FLFtDeq"
      },
      "outputs": [],
      "source": [
        "plot_output_windowed(test_data, 0)\n",
        "plot_input_covariate_windowed(test_data, 0, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLSMdUb0jqaD"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08ScNh4vtcq3"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        '''\n",
        "        We define a recurrent network that predicts the \n",
        "        future values of a time-dependent variable based on\n",
        "        past inputs and covariates.\n",
        "        '''\n",
        "        super(Network, self).__init__()\n",
        "        self.params = params\n",
        "        self.embedding = nn.Embedding(params['num_classes'], params['embedding_dim'])\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=params['cov_dim']+params['embedding_dim']+params['context_length']-1,\n",
        "                            hidden_size=params['lstm_hidden_dim'],\n",
        "                            num_layers=params['lstm_layers'],\n",
        "                            bias=True,\n",
        "                            batch_first=True,\n",
        "                          )\n",
        "\n",
        "        self.distribution_mu = nn.Linear(params['lstm_hidden_dim'], 1)\n",
        "        self.distribution_presigma = nn.Linear(params['lstm_hidden_dim'], 1)\n",
        "        self.distribution_sigma = nn.Softplus()\n",
        "\n",
        "\n",
        "    def forward(self, x, h0_c0=None):\n",
        "        '''\n",
        "        Predict mu and sigma of the distribution for z_t.\n",
        "        '''\n",
        "        cov = x[:, :, :-1]   # remove the company index from the inputs to get the covariates\n",
        "\n",
        "        company_index = x[:, 0, -1].to(torch.int32)  # retrieve the company index from the covariates\n",
        "        # print(\"company_index = \", company_index)\n",
        "        # print(\"params['num_classes'] = \", params['num_classes'])\n",
        "        # print(\"params['embedding_dim'] = \", params['embedding_dim'])\n",
        "        onehot_embed = self.embedding(company_index)\n",
        "        batch_size = cov.shape[0]\n",
        "        seq_len = cov.shape[1]\n",
        "        cov_dim = cov.shape[2]\n",
        "        # print(cov_dim)\n",
        "        # print(params['cov_dim']+params['context_length']-1)\n",
        "        assert cov_dim == params['cov_dim']+params['context_length']-1\n",
        "        assert batch_size <= params['batch_size']\n",
        "\n",
        "        ohe_embed_all_timestamps = onehot_embed.unsqueeze(1).repeat(1,seq_len,1)\n",
        "\n",
        "        lstm_input = torch.cat(\n",
        "            (cov,\n",
        "             ohe_embed_all_timestamps\n",
        "            ), dim=2\n",
        "          )\n",
        "        \n",
        "        assert lstm_input.shape[0] <= params['batch_size']\n",
        "        assert lstm_input.shape[1] == seq_len\n",
        "        assert lstm_input.shape[2] == params['cov_dim'] + params['embedding_dim']+params['context_length']-1\n",
        "\n",
        "        out1, hn_cn = self.lstm(input=lstm_input, hx=h0_c0)\n",
        "              \n",
        "        out_mu = self.distribution_mu(out1)\n",
        "        \n",
        "        out_presigma = self.distribution_presigma(out1)\n",
        "        out_sigma = self.distribution_sigma(out_presigma)\n",
        "\n",
        "        return out_mu, out_sigma, hn_cn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ5OtTaYfseM"
      },
      "outputs": [],
      "source": [
        "model = Network(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftx2ntzyfucg",
        "outputId": "69246b21-814d-468d-dfe7-820c8fd6e027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "out mu shape torch.Size([32, 192, 1])\n",
            "out_sigma shape torch.Size([32, 192, 1])\n",
            "ht shape torch.Size([4, 32, 256]) torch.Size([4, 32, 256])\n"
          ]
        }
      ],
      "source": [
        "for i, (ip_covariate, op_label) in enumerate(train_loader):\n",
        "  out_mu, out_sigma, ht_ct = model.forward(x=ip_covariate)\n",
        "\n",
        "  print('out mu shape', out_mu.shape)\n",
        "  print('out_sigma shape', out_sigma.shape)\n",
        "  print('ht shape', ht_ct[0].shape, ht_ct[1].shape)\n",
        "\n",
        "\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzRdJQOgf6jN"
      },
      "outputs": [],
      "source": [
        "def loss_fn(mu,sigma,labels):\n",
        "  mu = torch.squeeze(mu)\n",
        "  sigma = torch.squeeze(sigma)\n",
        "  total_likelihood = 0\n",
        "  for i in range(mu.shape[0]):  # loop through batch\n",
        "    for j in range(mu.shape[1]):# each batch  loop through time steps\n",
        "      distribution = torch.distributions.normal.Normal(mu[i][j] , sigma[i][j]) # scaling the values by 10 to avoid small sigma values\n",
        "      total_likelihood += distribution.log_prob(labels[i][j])\n",
        "  return -1*total_likelihood/(mu.shape[0]*mu.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jm5a4Llp2zED"
      },
      "outputs": [],
      "source": [
        "def loss_fn_updated(mu,sigma,labels):\n",
        "\n",
        "  batch,seq_len,mudim = mu.shape\n",
        "  batch,seq_len,sigmadim = sigma.shape\n",
        "\n",
        "  assert mudim==sigmadim\n",
        "\n",
        "  mu = mu.view(batch*seq_len,mudim)\n",
        "  sigma = sigma.view(batch*seq_len,sigmadim)\n",
        "  labels = labels.view(batch*seq_len,1)\n",
        "\n",
        "  gauss_prices = torch.distributions.Normal(mu,sigma)\n",
        "  total_likelihood = -1 * torch.sum(gauss_prices.log_prob(labels))/(batch*seq_len)\n",
        "\n",
        "  return total_likelihood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eC-xgKchn2v",
        "outputId": "fa4bd11a-86fe-4683-92ed-fd6d0b237c8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "orginal loss fn tensor([49.4699])\n",
            "update loss fn tensor(49.4699)\n"
          ]
        }
      ],
      "source": [
        "out_price_mu = torch.randn(4, 8, 1)\n",
        "out_price_sigma = torch.rand(4, 8, 1)\n",
        "op_label_price = torch.rand(4, 8, 1)\n",
        "\n",
        "print(\"orginal loss fn\",loss_fn(out_price_mu, out_price_sigma,op_label_price))\n",
        "print(\"update loss fn\",loss_fn_updated(out_price_mu, out_price_sigma,op_label_price))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKuPV1V5rPup"
      },
      "outputs": [],
      "source": [
        "def rmse(overall_mu, overall_label):\n",
        "  predictions = overall_mu.cpu().detach().numpy()\n",
        "  labels = overall_label.cpu().detach().numpy()\n",
        "\n",
        "  N, T = predictions.shape\n",
        "  numerator = np.sqrt((1/(N*T)) *np.sum((predictions - labels) ** 2))\n",
        "\n",
        "  denominator = (1/(N*T)) *np.sum(np.abs(labels))\n",
        "  result =numerator/denominator\n",
        "\n",
        "  return result\n",
        "\n",
        "def ND(overall_mu, overall_label):\n",
        "  predictions = overall_mu.cpu().detach().numpy()\n",
        "  labels = overall_label.cpu().detach().numpy()\n",
        "\n",
        "  N, T = predictions.shape\n",
        "  numerator = np.sum(np.abs(labels - predictions))\n",
        "\n",
        "  denominator = np.sum(np.abs(labels))\n",
        "  result =numerator/denominator\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yh49qzJUhv9r"
      },
      "outputs": [],
      "source": [
        "conditionining_period = params['conditioning_period']\n",
        "prediction_period     = params['prediction_period']\n",
        "\n",
        "assert conditionining_period + prediction_period == params['window_size']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgRhFbUxhz3S"
      },
      "outputs": [],
      "source": [
        "def validate(model):\n",
        "\n",
        "  model.eval()\n",
        "  model.cuda()\n",
        "  total_RMSE = 0\n",
        "\n",
        "  overall_mu = None\n",
        "  overall_sigma = None\n",
        "  overall_label = None\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # batch_bar = tqdm(total=len(test_loader), dynamic_ncols=True, leave=False, position=0, desc='Test') \n",
        "\n",
        "    for i, (ip_covariate, op_label) in enumerate(test_loader):\n",
        "      ip_covariate = ip_covariate.cuda()\n",
        "      op_label     = op_label.cuda()\n",
        "\n",
        "      cond_ip = ip_covariate[:, 0:conditionining_period, :]\n",
        "      cond_op = op_label[:, 0:conditionining_period]\n",
        "\n",
        "      pred_ip = ip_covariate[:, conditionining_period: , :]\n",
        "      pred_op = op_label[:,  conditionining_period: ]\n",
        "\n",
        "      # Step One - Forward Pass : Conditioning Period\n",
        "      # print(cond_ip.shape) \n",
        "      mu, sigma, ht_ct = model(x=cond_ip, h0_c0=None)\n",
        "\n",
        "      batch_mu = mu.squeeze()\n",
        "      batch_sigma = sigma.squeeze()\n",
        "\n",
        "      # Initialize pred_mu for the first time instance of the \"prediction period\"\n",
        "      # from the value of the \"predicted mu\" from the last CONTEXT LENGTH VALUES of the \"conditioning period\"\n",
        "      pred_mu, pred_sigma = mu[:, -params['context_length']:, :], sigma[:, -1, :].unsqueeze(1)\n",
        "      # print(\"pred_mu\")\n",
        "      # print(pred_mu)\n",
        "      # print(\"pred_mu shape\",pred_mu.shape)\n",
        "\n",
        "      for t in range(0, prediction_period):\n",
        "\n",
        "        #setting the covariates to the ones recieved from data loader\n",
        "        pred_cov_ip = pred_ip[:, t, :].unsqueeze(1)\n",
        "        # print(\"initial input\")\n",
        "        # print(pred_cov_ip)\n",
        "\n",
        "        #overwriting the opening price (t-1),(t-2),(t-3)\n",
        "        for i in range(params['context_length']):\n",
        "          # print(\"pred_cov_ip[:, 0, i]\",pred_cov_ip[:, 0, i].shape)\n",
        "          # print(\"pred_mu[:,:, 0]\",pred_mu[:, :, 0].shape)\n",
        "          pred_cov_ip[:, 0, i] = pred_mu[:, -(i+1), 0].squeeze()\n",
        "        \n",
        "        # print(\"overwritten input\")\n",
        "        # print(pred_cov_ip)\n",
        "        \n",
        "        mu, pred_sigma, ht_ct = model(x=pred_cov_ip, h0_c0=ht_ct)\n",
        "        \n",
        "        pred_mu = torch.roll(pred_mu, shifts=-1, dims=1)\n",
        "        pred_mu[:,-1,:] = mu.squeeze(1)\n",
        "        \n",
        "        batch_mu = torch.cat((batch_mu,  mu.squeeze(1)), dim=1)\n",
        "        batch_sigma = torch.cat((batch_sigma, pred_sigma.squeeze(2)), dim=1)\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "      if overall_mu is None and overall_sigma is None:\n",
        "        overall_mu = batch_mu\n",
        "        overall_sigma = batch_sigma\n",
        "        overall_label = op_label\n",
        "      else:\n",
        "        overall_mu = torch.cat((overall_mu,  batch_mu), dim=0)\n",
        "        overall_sigma = torch.cat((overall_sigma, batch_sigma), dim=0)\n",
        "        overall_label = torch.cat((overall_label, op_label), dim=0)\n",
        "        \n",
        "    rmse_val = rmse(overall_mu[:, params['conditioning_period']:], overall_label[:, params['conditioning_period']:])\n",
        "    nd_val = ND(overall_mu[:, params['conditioning_period']:], overall_label[:, params['conditioning_period']:])\n",
        "\n",
        "  return rmse_val,nd_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwuPKOhxlE55"
      },
      "outputs": [],
      "source": [
        "def plot_output_data(data, window_id):\n",
        "  # 1st index is output (prediction)\n",
        "  x=np.linspace(1, len(data[window_id]), num=len(data[window_id]))\n",
        "  fig = px.line(x=x, y=data[window_id])\n",
        "  fig.show()\n",
        "  # print(\"op\", data[window_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx7T3s1OlVlR"
      },
      "outputs": [],
      "source": [
        "validate(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACcXCFb8ms4G",
        "outputId": "87b32a53-b53c-4420-ca2c-c1f851dcd857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([96, 192, 6])\n"
          ]
        }
      ],
      "source": [
        "for i, (ip_covariate, op_label) in enumerate(train_loader):\n",
        "  print(ip_covariate.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "GcqzdhqsxMP9",
        "outputId": "5f86b7d0-19bd-4327-f063-69bf7cf13904"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 85.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 59.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztGXKfg3xSXY"
      },
      "outputs": [],
      "source": [
        "# wandb.init(project=\"final-results\", entity=\"idl-deepar-spring-22\", name=\"context_without_volume\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2pQS5w42h9H",
        "outputId": "a48d9b01-200e-4d21-c028-a66bf0f229d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (embedding): Embedding(249, 128)\n",
            "  (lstm): LSTM(140, 256, num_layers=4, batch_first=True)\n",
            "  (distribution_mu): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (distribution_presigma): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (distribution_sigma): Softplus(beta=1, threshold=20)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100: Train Loss -1.6330, Learning Rate 0.0020\n",
            "rmse is  0.48003882813409704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/100: Train Loss -2.3112, Learning Rate 0.0020\n",
            "rmse is  0.3787038499750919\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/100: Train Loss -2.8045, Learning Rate 0.0020\n",
            "rmse is  0.33787413829130875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/100: Train Loss -3.0201, Learning Rate 0.0020\n",
            "rmse is  0.37202484658950036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/100: Train Loss 60.5619, Learning Rate 0.0020\n",
            "rmse is  0.754083412191906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/100: Train Loss 1.6221, Learning Rate 0.0020\n",
            "rmse is  0.6675627458848137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/100: Train Loss -0.1618, Learning Rate 0.0020\n",
            "rmse is  0.5418983317575002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/100: Train Loss -0.4442, Learning Rate 0.0020\n",
            "rmse is  0.5418273504613493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/100: Train Loss -0.4436, Learning Rate 0.0014\n",
            "rmse is  0.5465925583870659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/100: Train Loss -0.4441, Learning Rate 0.0014\n",
            "rmse is  0.5538579763844533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/100: Train Loss -0.4434, Learning Rate 0.0014\n",
            "rmse is  0.5487808135919686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/100: Train Loss -0.4426, Learning Rate 0.0014\n",
            "rmse is  0.5665953406517116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/100: Train Loss -0.4414, Learning Rate 0.0014\n",
            "rmse is  0.551424369467914\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/100: Train Loss -0.4391, Learning Rate 0.0014\n",
            "rmse is  0.5482445829137779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/100: Train Loss -0.4376, Learning Rate 0.0014\n",
            "rmse is  0.5525921680623659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/100: Train Loss -0.4375, Learning Rate 0.0014\n",
            "rmse is  0.5667925789731042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/100: Train Loss -0.4376, Learning Rate 0.0010\n",
            "rmse is  0.5544613350433902\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/100: Train Loss -0.4386, Learning Rate 0.0010\n",
            "rmse is  0.5513347850097577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/100: Train Loss -0.4378, Learning Rate 0.0010\n",
            "rmse is  0.5465643313120782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  93%|█████████▎| 14480/15625 [8:29:13<3:02:15,  9.55s/it, loss=-0.4379, lr=0.0010]"
          ]
        }
      ],
      "source": [
        "model_version='deepar_model_no_volume_v1.pt'\n",
        "epochs = params['epochs']\n",
        "\n",
        "best_dev_rmse = 10000\n",
        "\n",
        "model = Network(params)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
        "#scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=5, threshold=0.01, threshold_mode='rel', cooldown=2, min_lr=0, eps=1e-08, verbose=False)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "print(model)\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "    model.train()\n",
        "    model.cuda()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "\n",
        "    for i, (ip_covariate, op_label) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ip_covariate = ip_covariate.cuda()\n",
        "        # print(ip_covariate.shape)\n",
        "        op_label     = op_label.cuda()\n",
        "\n",
        "        mu, sigma, ht_ct = model(x=ip_covariate, h0_c0=None)\n",
        "\n",
        "        # print('mu shape', mu.shape, 'sigma shape', sigma.shape, 'op label', op_label.shape)\n",
        "        loss = loss_fn_updated(mu, sigma, op_label)\n",
        "\n",
        "        # print(\"loss\", loss)\n",
        "\n",
        "        total_loss += float(loss)\n",
        "        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "        scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "        scaler.update()\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "\n",
        "        # tqdm lets you add some details so you can monitor training as you train.\n",
        "        batch_bar.set_postfix(\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "        \n",
        "        batch_bar.update() \n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "    val_rmse, val_nd= validate(model=model)\n",
        "    scheduler.step(val_rmse)\n",
        "    running_loss = total_loss/len(train_loader)\n",
        "    # wandb.log({'lr': optimizer.param_groups[0]['lr'], 'Train_loss': running_loss, 'rmse':val_rmse, 'ND':val_nd })\n",
        "\n",
        "    torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': total_loss/len(train_loader),\n",
        "            },  f'/content/drive/MyDrive/Shreya_Project/{1}')\n",
        "  \n",
        "\n",
        "    if val_rmse < best_dev_rmse:\n",
        "      best_dev_rmse = val_rmse\n",
        "    print(\"Epoch {}/{}: Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n",
        "        epoch + 1,\n",
        "        epochs,\n",
        "        float(total_loss / len(train_loader)),\n",
        "        float(optimizer.param_groups[0]['lr'])))\n",
        "    print(\"rmse is \", val_rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "VruLf-iBfuYC",
        "outputId": "4f89b61c-ed3c-4262-ecd9-f2520c98f9ec"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-d335bad2c794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/DeepARExperiments/deepar_model_no_volume_v1.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1498\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1499\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([242, 64]) from checkpoint, the shape in current model is torch.Size([257, 64])."
          ]
        }
      ],
      "source": [
        "checkpoint = torch.load(f'/content/drive/MyDrive/DeepARExperiments/deepar_model_no_volume_v1.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k85MEGHz6iIt"
      },
      "outputs": [],
      "source": [
        "import torch.distributions\n",
        "def get_pred_sigma_mu_labels(model):\n",
        "\n",
        "  model.eval()\n",
        "  model.cuda()\n",
        "\n",
        "\n",
        "  total_RMSE = 0\n",
        "\n",
        "  overall_mu = None\n",
        "  overall_sigma = None\n",
        "  overall_label = None\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # batch_bar = tqdm(total=len(test_loader), dynamic_ncols=True, leave=False, position=0, desc='Test') \n",
        "\n",
        "    for i, (ip_covariate, op_label) in enumerate(test_loader):\n",
        "      ip_covariate = ip_covariate.cuda()\n",
        "      op_label     = op_label.cuda()\n",
        "\n",
        "      cond_ip = ip_covariate[:, 0:conditionining_period, :]\n",
        "      cond_op = op_label[:, 0:conditionining_period]\n",
        "\n",
        "      pred_ip = ip_covariate[:, conditionining_period: , :]\n",
        "      pred_op = op_label[:,  conditionining_period: ]\n",
        "\n",
        "      # Step One - Forward Pass : Conditioning Period    \n",
        "      mu, sigma, ht_ct = model(x=cond_ip, h0_c0=None)\n",
        "\n",
        "\n",
        "      batch_mu = mu.squeeze()\n",
        "      batch_sigma = sigma.squeeze()\n",
        "      \n",
        "\n",
        "      # Initialize pred_mu for the first time instance of the \"prediction period\"\n",
        "      # from the value of the \"predicted mu\" from the last instance of the \"conditioning period\"\n",
        "      pred_mu, pred_sigma = mu[:, -params['context_length']:, :], sigma[:, -1, :].unsqueeze(1) #-> pred_mu [BxTx1]\n",
        "      \n",
        "      # m = torch.distributions.Normal(pred_mu, pred_sigma)\n",
        "      # sample = m.sample()\n",
        "      # sample_pred = sample.squeeze()\n",
        "      # batch_sampled = mu.squeeze()\n",
        "      # batch_sampled[:,-1] = sample.squeeze()\n",
        "\n",
        "      # print(\"batch mu initial shape\", batch_mu.shape)\n",
        "      # print(\"batch sampled initial shape\", batch_sampled.shape)\n",
        "\n",
        "      for t in range(0, prediction_period):\n",
        "        pred_cov_ip = pred_ip[:, t, :].unsqueeze(1)\n",
        "        # pred_cov_ip[:, 0, 0] = pred_mu[:, 0, 0]\n",
        "        for i in range(params['context_length']):\n",
        "          # print(\"pred_cov_ip[:, 0, i]\",pred_cov_ip[:, 0, i].shape)\n",
        "          # print(\"pred_mu[:,:, 0]\",pred_mu[:, :, 0].shape)\n",
        "          pred_cov_ip[:, 0, i] = pred_mu[:, -(i+1), 0].squeeze()\n",
        "\n",
        "        mu, pred_sigma, ht_ct = model(x=pred_cov_ip, h0_c0=ht_ct)\n",
        "\n",
        "        pred_mu = torch.roll(pred_mu, shifts=-1, dims=1)\n",
        "        pred_mu[:,-1,:] = mu.squeeze(1)\n",
        "        \n",
        "        batch_mu = torch.cat((batch_mu,  mu.squeeze(2)), dim=1)\n",
        "\n",
        "        # m = torch.distributions.Normal(pred_mu, pred_sigma)\n",
        "        # sample = m.sample()\n",
        "        # sample_pred = sample.squeeze()\n",
        "        # batch_sampled = torch.cat((batch_sampled,  sample.squeeze(2)), dim=1)\n",
        "\n",
        "        # print(\"batch mu updated shape\", batch_mu.shape)\n",
        "        # print(\"batch sampled updated shape\", batch_sampled.shape)\n",
        "\n",
        "\n",
        "\n",
        "        batch_sigma = torch.cat((batch_sigma, pred_sigma.squeeze(2)), dim=1)\n",
        "\n",
        "\n",
        "      if overall_mu is None and overall_sigma is None:\n",
        "        # overall_samples = batch_sampled\n",
        "        overall_mu = batch_mu\n",
        "        overall_sigma = batch_sigma\n",
        "        overall_label = op_label\n",
        "      else:\n",
        "        overall_mu = torch.cat((overall_mu,  batch_mu), dim=0)\n",
        "        # overall_samples = torch.cat((overall_samples,  batch_sampled), dim=0)\n",
        "        overall_sigma = torch.cat((overall_sigma, batch_sigma), dim=0)\n",
        "        overall_label = torch.cat((overall_label, op_label), dim=0)\n",
        "  \n",
        "\n",
        "    # print(\"Shape of batch_mu\", batch_mu.shape)\n",
        "    # print(\"Shape of batch_sampled\", batch_sampled.shape)\n",
        "\n",
        "  return  overall_mu, overall_sigma, overall_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R1QqTrR-I7U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "def plot_test_output_data(actual,predicted, sigma, window_id):\n",
        "  print(\"Predicted = \", predicted)\n",
        "  x=np.linspace(1, len(actual[window_id]), num=len(actual[window_id]))\n",
        "  df = pd.DataFrame()\n",
        "  df['actual'] = actual[window_id]\n",
        "  df['predicted'] = predicted[window_id]\n",
        "  #df['sampled']=sampled[window_id]\n",
        "  df['predicted_upper'] = predicted[window_id] + 1*sigma[window_id]\n",
        "  df['predcited_lower'] = predicted[window_id] - 1*sigma[window_id]\n",
        "  # print(\"df predicted = \", df['predicted'])\n",
        "\n",
        "  fig = go.Figure()\n",
        "  fig.add_vline(x=168)\n",
        "  fig.add_traces(go.Scatter(x=x, y = df['actual'], mode = 'lines', name = 'Actual'))\n",
        "  fig.add_traces(go.Scatter(x=x, y = df['predicted'], mode = 'lines', name = 'Predicted'))\n",
        "  #fig.add_traces(go.Scatter(x=x, y = df['sampled'], mode = 'lines', name = 'Sampled'))\n",
        "\n",
        "  fig.add_traces(go.Scatter(\n",
        "        name='Upper Bound',\n",
        "        x=x.tolist(),\n",
        "        y=df['predicted_upper'],\n",
        "        mode='lines',\n",
        "        marker=dict(color=\"#444\"),\n",
        "        line=dict(width=0),\n",
        "        showlegend=False\n",
        "    ))\n",
        "  fig.add_traces(\n",
        "    go.Scatter(\n",
        "        name='Lower Bound',\n",
        "        x=x.tolist(),\n",
        "        y= df['predcited_lower'],\n",
        "        marker=dict(color=\"#444\"),\n",
        "        line=dict(width=0),\n",
        "        mode='lines',\n",
        "        fillcolor='rgba(68, 68, 68, 0.3)',\n",
        "        fill='tonexty',\n",
        "        showlegend=False\n",
        "    ))\n",
        "  \n",
        "\n",
        "  fig.update_xaxes(title_text='Time Samples')\n",
        "  fig.update_yaxes(title_text='Normalized Stock Opening Price')\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "N3fq-HYm-Pjm",
        "outputId": "cd0f9fe5-1932-4bd0-9c4e-882a279af546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted =  [[ 0.08060318  0.0964447   0.08848543 ... -1.2808992  -1.3600297\n",
            "  -1.4419509 ]\n",
            " [ 0.08421507  0.07817522  0.07991835 ... -1.7238387  -1.875146\n",
            "  -1.8674041 ]\n",
            " [ 0.05651615  0.07341048  0.0761237  ... -1.5437918  -1.5742885\n",
            "  -1.5820243 ]\n",
            " ...\n",
            " [ 0.37381244  0.37854525  0.37531224 ...  0.6001734   0.5761881\n",
            "   0.60553   ]\n",
            " [ 0.37621233  0.36282602  0.40395933 ...  0.5463468   0.5756979\n",
            "   0.60877925]\n",
            " [ 0.41492218  0.4015922   0.46570712 ...  0.53073996  0.5435107\n",
            "   0.51875055]]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"d41c50ce-9f9f-4b09-9b3d-0111db762366\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d41c50ce-9f9f-4b09-9b3d-0111db762366\")) {                    Plotly.newPlot(                        \"d41c50ce-9f9f-4b09-9b3d-0111db762366\",                        [{\"mode\":\"lines\",\"name\":\"Actual\",\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0,51.0,52.0,53.0,54.0,55.0,56.0,57.0,58.0,59.0,60.0,61.0,62.0,63.0,64.0,65.0,66.0,67.0,68.0,69.0,70.0,71.0,72.0,73.0,74.0,75.0,76.0,77.0,78.0,79.0,80.0,81.0,82.0,83.0,84.0,85.0,86.0,87.0,88.0,89.0,90.0,91.0,92.0,93.0,94.0,95.0,96.0,97.0,98.0,99.0,100.0,101.0,102.0,103.0,104.0,105.0,106.0,107.0,108.0,109.0,110.0,111.0,112.0,113.0,114.0,115.0,116.0,117.0,118.0,119.0,120.0,121.0,122.0,123.0,124.0,125.0,126.0,127.0,128.0,129.0,130.0,131.0,132.0,133.0,134.0,135.0,136.0,137.0,138.0,139.0,140.0,141.0,142.0,143.0,144.0,145.0,146.0,147.0,148.0,149.0,150.0,151.0,152.0,153.0,154.0,155.0,156.0,157.0,158.0,159.0,160.0,161.0,162.0,163.0,164.0,165.0,166.0,167.0,168.0,169.0,170.0,171.0,172.0,173.0,174.0,175.0,176.0,177.0,178.0,179.0,180.0,181.0,182.0,183.0,184.0,185.0,186.0,187.0,188.0,189.0,190.0,191.0,192.0],\"y\":[0.2696579098701477,0.27165737748146057,0.24059084057807922,0.24140529334545135,0.2283252626657486,0.23283334076404572,0.21265549957752228,0.2462834268808365,0.22133368253707886,0.19474074244499207,0.2030976265668869,0.21555334329605103,0.1972523033618927,0.2495274394750595,0.2656516134738922,0.2820153534412384,0.2744525074958801,0.2930971384048462,0.29900306463241577,0.28875255584716797,0.2891480028629303,0.29743021726608276,0.31581592559814453,0.31114134192466736,0.31425923109054565,0.3200892508029938,0.31581592559814453,0.3806413412094116,0.3840026259422302,0.3753989040851593,0.3772731423377991,0.384375661611557,0.3921900689601898,0.3817625343799591,0.3881014883518219,0.4054998755455017,0.40513160824775696,0.3970089256763458,0.39959779381752014,0.37914520502090454,0.38138890266418457,0.36901038885116577,0.35691675543785095,0.3274442255496979,0.3584333658218384,0.36297476291656494,0.38138890266418457,0.3940451741218567,0.40033671259880066,0.3772731423377991,0.3903329074382782,0.3866121768951416,0.39070451259613037,0.3970089256763458,0.406604140996933,0.39885851740837097,0.3780222237110138,0.41101378202438354,0.39070451259613037,0.3936743140220642,0.3810151517391205,0.36297476291656494,0.3462608754634857,0.371643990278244,0.3765237033367157,0.39515718817710876,0.34969356656074524,0.3359193205833435,0.3451150357723236,0.35956987738609314,0.3656180799007416,0.3576752245426178,0.37239566445350647,0.3840026259422302,0.3652407228946686,0.3181482255458832,0.3313019871711731,0.29782357811927795,0.2680565416812897,0.26685452461242676,0.2511470317840576,0.26765596866607666,0.2816181778907776,0.23201462626457214,0.20142966508865356,0.22791482508182526,0.18254682421684265,0.20684432983398438,0.23773710429668427,0.24262619018554688,0.23896074295043945,0.23487836122512817,0.23814508318901062,0.2487170398235321,0.2792331278324127,0.28716981410980225,0.27285587787628174,0.2572062611579895,0.2555926740169525,0.18781398236751556,0.17196127772331238,0.1980886310338974,0.1662164330482483,0.19641554355621338,0.22421619296073914,0.24425263702869415,0.27365440130233765,0.2555926740169525,0.2776411473751068,0.2776411473751068,0.24059084057807922,0.276446133852005,0.30018168687820435,0.28518927097320557,0.2891480028629303,0.3173711597919464,0.32860249280929565,0.3282164931297302,0.3228028416633606,0.31231123208999634,0.31425923109054565,0.33284255862236023,0.3405236601829529,0.3443506956100464,0.3447329103946686,0.34969356656074524,0.37314698100090027,0.3802674412727356,0.37277135252952576,0.3746486008167267,0.3802674412727356,0.3659953474998474,0.37914520502090454,0.3705158233642578,0.4073399007320404,0.4062361419200897,0.3936743140220642,0.41504549980163574,0.40070605278015137,0.39589813351631165,0.39959779381752014,0.39626848697662354,0.3947865962982178,0.3862396478652954,0.4040263593196869,0.40881043672561646,0.4084429442882538,0.39959779381752014,0.4143131971359253,0.4036577641963959,0.4032890796661377,0.3735225200653076,0.36637255549430847,0.37314698100090027,0.34243831038475037,0.3584333658218384,0.32589855790138245,0.32435142993927,0.3216404318809509,0.31036093831062317,0.3173711597919464,0.3064533472061157,0.32628509402275085,0.33053117990493774,0.34243831038475037,0.3409067690372467,0.32975998520851135,0.3255119025707245,0.34167271852493286,0.32589855790138245,0.3293742537498474,0.3332274854183197,0.3432035446166992,0.34740591049194336,0.3780222237110138,0.3825095593929291,0.3873569965362549,0.3970089256763458,0.39330339431762695,0.3881014883518219,0.3910760283470154,0.39070451259613037,0.39774900674819946,0.39885851740837097,0.39589813351631165,0.3903329074382782,0.37577393651008606,0.36825716495513916,0.3783966302871704,0.36335262656211853,0.36373043060302734,0.3705158233642578],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Predicted\",\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0,51.0,52.0,53.0,54.0,55.0,56.0,57.0,58.0,59.0,60.0,61.0,62.0,63.0,64.0,65.0,66.0,67.0,68.0,69.0,70.0,71.0,72.0,73.0,74.0,75.0,76.0,77.0,78.0,79.0,80.0,81.0,82.0,83.0,84.0,85.0,86.0,87.0,88.0,89.0,90.0,91.0,92.0,93.0,94.0,95.0,96.0,97.0,98.0,99.0,100.0,101.0,102.0,103.0,104.0,105.0,106.0,107.0,108.0,109.0,110.0,111.0,112.0,113.0,114.0,115.0,116.0,117.0,118.0,119.0,120.0,121.0,122.0,123.0,124.0,125.0,126.0,127.0,128.0,129.0,130.0,131.0,132.0,133.0,134.0,135.0,136.0,137.0,138.0,139.0,140.0,141.0,142.0,143.0,144.0,145.0,146.0,147.0,148.0,149.0,150.0,151.0,152.0,153.0,154.0,155.0,156.0,157.0,158.0,159.0,160.0,161.0,162.0,163.0,164.0,165.0,166.0,167.0,168.0,169.0,170.0,171.0,172.0,173.0,174.0,175.0,176.0,177.0,178.0,179.0,180.0,181.0,182.0,183.0,184.0,185.0,186.0,187.0,188.0,189.0,190.0,191.0,192.0],\"y\":[0.2735883295536041,0.28354397416114807,0.28044116497039795,0.2587830424308777,0.25813955068588257,0.2478892207145691,0.22525092959403992,0.21306830644607544,0.239078551530838,0.2324906885623932,0.19885917007923126,0.21414047479629517,0.20420067012310028,0.18899627029895782,0.25172537565231323,0.27508383989334106,0.27733033895492554,0.2777138650417328,0.27303770184516907,0.2822610139846802,0.2995631992816925,0.29891571402549744,0.31445619463920593,0.3145237863063812,0.31656768918037415,0.3341870605945587,0.3234633803367615,0.31664392352104187,0.36060965061187744,0.3902718424797058,0.3942451775074005,0.38520756363868713,0.39071014523506165,0.4029945433139801,0.3676573634147644,0.3912048041820526,0.43116334080696106,0.3823038339614868,0.3930177390575409,0.3544577956199646,0.33167240023612976,0.3703421950340271,0.3630325198173523,0.3767411410808563,0.34670940041542053,0.3489510118961334,0.3615657687187195,0.4046025276184082,0.42553016543388367,0.3821036219596863,0.37383928894996643,0.41894224286079407,0.3957289159297943,0.3941929042339325,0.3660041391849518,0.42035111784935,0.41934216022491455,0.37811335921287537,0.38458630442619324,0.341117799282074,0.4027419686317444,0.37274062633514404,0.3491222858428955,0.3256974518299103,0.3402961194515228,0.3874525725841522,0.39501529932022095,0.39895403385162354,0.3589017391204834,0.3625791072845459,0.35463908314704895,0.38121289014816284,0.35033920407295227,0.3777379095554352,0.37876999378204346,0.33119669556617737,0.28737035393714905,0.3137820065021515,0.2874578535556793,0.25837668776512146,0.26121366024017334,0.18188464641571045,0.23142096400260925,0.29091060161590576,0.2745569050312042,0.22493791580200195,0.18289396166801453,0.17434793710708618,0.24649035930633545,0.2605897784233093,0.22594812512397766,0.19505886733531952,0.20076824724674225,0.21807101368904114,0.24692311882972717,0.30101898312568665,0.2930329442024231,0.3117065131664276,0.25085657835006714,0.24188685417175293,0.2431197464466095,0.2336699664592743,0.22937968373298645,0.20178700983524323,0.19260331988334656,0.2158014178276062,0.2915645241737366,0.22614771127700806,0.2553146183490753,0.28704118728637695,0.2538311779499054,0.22273588180541992,0.3134572207927704,0.27986738085746765,0.3315218687057495,0.3238232135772705,0.32225289940834045,0.3318970501422882,0.28203925490379333,0.26181307435035706,0.2964234948158264,0.28625863790512085,0.31592509150505066,0.3290742337703705,0.34010717272758484,0.3544488251209259,0.36727598309516907,0.39162445068359375,0.40311697125434875,0.38743457198143005,0.3772421181201935,0.3769327700138092,0.3577686548233032,0.38611459732055664,0.3790104389190674,0.40251418948173523,0.4026068150997162,0.39223599433898926,0.41009512543678284,0.431721568107605,0.3543720841407776,0.39910218119621277,0.3888368308544159,0.3578886091709137,0.3892175555229187,0.3864001929759979,0.40321287512779236,0.40827611088752747,0.4124329388141632,0.43121081590652466,0.41395047307014465,0.4084365665912628,0.3664643466472626,0.36494535207748413,0.37052303552627563,0.34275349974632263,0.36309587955474854,0.31790632009506226,0.3272643983364105,0.3175439238548279,0.3218716084957123,0.31312087178230286,0.31125760078430176,0.33556824922561646,0.32983407378196716,0.3516845107078552,0.33853769302368164,0.3228573501110077,0.3267609477043152,0.33112943172454834,0.34151560068130493,0.3459083139896393,0.35093173384666443,0.3534868657588959,0.3553416430950165,0.35773414373397827,0.3594284653663635,0.36233845353126526,0.36249399185180664,0.35222506523132324,0.33749738335609436,0.34656256437301636,0.3611903786659241,0.3632209599018097,0.36698684096336365,0.37083864212036133,0.37497642636299133,0.37639081478118896,0.3758472204208374,0.36602410674095154,0.3576151132583618,0.3594011664390564],\"type\":\"scatter\"},{\"line\":{\"width\":0},\"marker\":{\"color\":\"#444\"},\"mode\":\"lines\",\"name\":\"Upper Bound\",\"showlegend\":false,\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0,51.0,52.0,53.0,54.0,55.0,56.0,57.0,58.0,59.0,60.0,61.0,62.0,63.0,64.0,65.0,66.0,67.0,68.0,69.0,70.0,71.0,72.0,73.0,74.0,75.0,76.0,77.0,78.0,79.0,80.0,81.0,82.0,83.0,84.0,85.0,86.0,87.0,88.0,89.0,90.0,91.0,92.0,93.0,94.0,95.0,96.0,97.0,98.0,99.0,100.0,101.0,102.0,103.0,104.0,105.0,106.0,107.0,108.0,109.0,110.0,111.0,112.0,113.0,114.0,115.0,116.0,117.0,118.0,119.0,120.0,121.0,122.0,123.0,124.0,125.0,126.0,127.0,128.0,129.0,130.0,131.0,132.0,133.0,134.0,135.0,136.0,137.0,138.0,139.0,140.0,141.0,142.0,143.0,144.0,145.0,146.0,147.0,148.0,149.0,150.0,151.0,152.0,153.0,154.0,155.0,156.0,157.0,158.0,159.0,160.0,161.0,162.0,163.0,164.0,165.0,166.0,167.0,168.0,169.0,170.0,171.0,172.0,173.0,174.0,175.0,176.0,177.0,178.0,179.0,180.0,181.0,182.0,183.0,184.0,185.0,186.0,187.0,188.0,189.0,190.0,191.0,192.0],\"y\":[0.3146897256374359,0.3183249235153198,0.30608832836151123,0.29704397916793823,0.281833291053772,0.2741784453392029,0.24673405289649963,0.2337113469839096,0.2554190754890442,0.24482473731040955,0.22011201083660126,0.23173217475414276,0.22289502620697021,0.20884732902050018,0.2655879557132721,0.2952726483345032,0.32205116748809814,0.32119980454444885,0.28756335377693176,0.2888491153717041,0.3118037283420563,0.3164220154285431,0.3317282795906067,0.3325253427028656,0.3360578715801239,0.3577038049697876,0.33914610743522644,0.32711395621299744,0.36797091364860535,0.4032013416290283,0.4109531342983246,0.39560985565185547,0.39908140897750854,0.41179558634757996,0.38033029437065125,0.396883487701416,0.4398922324180603,0.4004257917404175,0.4147726893424988,0.3750647008419037,0.34046968817710876,0.3790326416492462,0.37012919783592224,0.38853976130485535,0.37504714727401733,0.39727649092674255,0.421416312456131,0.41409292817115784,0.4273386299610138,0.3842242658138275,0.3791360855102539,0.42434242367744446,0.40096166729927063,0.39948755502700806,0.37608590722084045,0.4230414628982544,0.4231531023979187,0.38756710290908813,0.39088502526283264,0.3480508625507355,0.40811392664909363,0.3763130307197571,0.35358455777168274,0.33035555481910706,0.3521134853363037,0.4037114679813385,0.4001559317111969,0.40117692947387695,0.36394575238227844,0.3685944080352783,0.36492228507995605,0.38732632994651794,0.35857075452804565,0.38700369000434875,0.3838202953338623,0.33622443675994873,0.2917463183403015,0.3173527717590332,0.29223155975341797,0.2828483581542969,0.3141295909881592,0.23117858171463013,0.2614764869213104,0.31302082538604736,0.3159133493900299,0.2607019245624542,0.1910889893770218,0.18339213728904724,0.2541419267654419,0.2668384611606598,0.23561476171016693,0.20093797147274017,0.20994235575199127,0.2284509688615799,0.2503156065940857,0.3035297989845276,0.2982274889945984,0.32058948278427124,0.25406214594841003,0.24610991775989532,0.26072704792022705,0.24258603155612946,0.2403731495141983,0.20933493971824646,0.2007247507572174,0.21885597705841064,0.2999196946620941,0.2383698970079422,0.25900763273239136,0.28994616866111755,0.2724404036998749,0.2534005343914032,0.3279830813407898,0.2827249765396118,0.3344807028770447,0.3341488540172577,0.3246651887893677,0.33578944206237793,0.295409232378006,0.26851585507392883,0.307052880525589,0.31269600987434387,0.33623918890953064,0.33977317810058594,0.3477396070957184,0.36416012048721313,0.3802226781845093,0.40439343452453613,0.41281387209892273,0.3947758674621582,0.3853077292442322,0.39432698488235474,0.3762744665145874,0.39920827746391296,0.38912609219551086,0.41438060998916626,0.4136999547481537,0.4225911498069763,0.4359298348426819,0.44852232933044434,0.3848770260810852,0.4369616210460663,0.4150142967700958,0.387830525636673,0.4226083755493164,0.40500813722610474,0.41207966208457947,0.41884222626686096,0.4218538701534271,0.4402131736278534,0.42385730147361755,0.4206543266773224,0.38996991515159607,0.3954862058162689,0.4069642424583435,0.37195414304733276,0.3909510374069214,0.34246283769607544,0.3455076813697815,0.34074866771698,0.36318543553352356,0.37012696266174316,0.35497957468032837,0.36060968041419983,0.3476223647594452,0.367568701505661,0.34843161702156067,0.3311644494533539,0.33359524607658386,0.3380917012691498,0.34904491901397705,0.3538314998149872,0.3591615557670593,0.361108660697937,0.3638920485973358,0.3676532208919525,0.3692994713783264,0.37244439125061035,0.37447187304496765,0.3672679662704468,0.3557392656803131,0.36668992042541504,0.3750830888748169,0.3752453029155731,0.37836241722106934,0.381491094827652,0.3829163610935211,0.38273006677627563,0.38377299904823303,0.37511563301086426,0.3660150170326233,0.3672090470790863],\"type\":\"scatter\"},{\"fill\":\"tonexty\",\"fillcolor\":\"rgba(68, 68, 68, 0.3)\",\"line\":{\"width\":0},\"marker\":{\"color\":\"#444\"},\"mode\":\"lines\",\"name\":\"Lower Bound\",\"showlegend\":false,\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0,51.0,52.0,53.0,54.0,55.0,56.0,57.0,58.0,59.0,60.0,61.0,62.0,63.0,64.0,65.0,66.0,67.0,68.0,69.0,70.0,71.0,72.0,73.0,74.0,75.0,76.0,77.0,78.0,79.0,80.0,81.0,82.0,83.0,84.0,85.0,86.0,87.0,88.0,89.0,90.0,91.0,92.0,93.0,94.0,95.0,96.0,97.0,98.0,99.0,100.0,101.0,102.0,103.0,104.0,105.0,106.0,107.0,108.0,109.0,110.0,111.0,112.0,113.0,114.0,115.0,116.0,117.0,118.0,119.0,120.0,121.0,122.0,123.0,124.0,125.0,126.0,127.0,128.0,129.0,130.0,131.0,132.0,133.0,134.0,135.0,136.0,137.0,138.0,139.0,140.0,141.0,142.0,143.0,144.0,145.0,146.0,147.0,148.0,149.0,150.0,151.0,152.0,153.0,154.0,155.0,156.0,157.0,158.0,159.0,160.0,161.0,162.0,163.0,164.0,165.0,166.0,167.0,168.0,169.0,170.0,171.0,172.0,173.0,174.0,175.0,176.0,177.0,178.0,179.0,180.0,181.0,182.0,183.0,184.0,185.0,186.0,187.0,188.0,189.0,190.0,191.0,192.0],\"y\":[0.23248693346977234,0.24876300990581512,0.25479400157928467,0.22052210569381714,0.23444581031799316,0.2215999960899353,0.2037678062915802,0.19242526590824127,0.22273801267147064,0.22015663981437683,0.17760632932186127,0.19654877483844757,0.18550631403923035,0.16914521157741547,0.23786279559135437,0.25489503145217896,0.23260951042175293,0.23422792553901672,0.25851204991340637,0.27567291259765625,0.28732267022132874,0.2814094126224518,0.2971841096878052,0.29652222990989685,0.2970775067806244,0.31067031621932983,0.3077806532382965,0.3061738908290863,0.35324838757514954,0.3773423433303833,0.37753722071647644,0.3748052716255188,0.38233888149261475,0.39419350028038025,0.35498443245887756,0.3855261206626892,0.4224344491958618,0.36418187618255615,0.371262788772583,0.3338508903980255,0.32287511229515076,0.361651748418808,0.35593584179878235,0.3649425208568573,0.31837165355682373,0.3006255328655243,0.301715224981308,0.39511212706565857,0.42372170090675354,0.37998297810554504,0.36854249238967896,0.4135420620441437,0.390496164560318,0.38889825344085693,0.3559223711490631,0.41766077280044556,0.4155312180519104,0.3686596155166626,0.37828758358955383,0.3341847360134125,0.39737001061439514,0.369168221950531,0.3446600139141083,0.3210393488407135,0.32847875356674194,0.37119367718696594,0.389874666929245,0.3967311382293701,0.35385772585868835,0.3565638065338135,0.34435588121414185,0.37509945034980774,0.3421076536178589,0.3684721291065216,0.3737196922302246,0.326168954372406,0.2829943895339966,0.3102112412452698,0.2826841473579407,0.23390503227710724,0.2082977294921875,0.13259071111679077,0.20136544108390808,0.26880037784576416,0.23320046067237854,0.18917390704154968,0.17469893395900726,0.16530373692512512,0.2388387769460678,0.25434109568595886,0.2162814885377884,0.18917976319789886,0.19159413874149323,0.20769105851650238,0.24353061616420746,0.2985081672668457,0.2878383994102478,0.302823543548584,0.24765101075172424,0.23766379058361053,0.22551245987415314,0.22475390136241913,0.2183862179517746,0.19423907995224,0.1844818890094757,0.21274685859680176,0.28320935368537903,0.2139255255460739,0.2516216039657593,0.28413620591163635,0.2352219521999359,0.19207122921943665,0.298931360244751,0.2770097851753235,0.32856303453445435,0.3134975731372833,0.31984061002731323,0.3280046582221985,0.2686692774295807,0.2551102936267853,0.28579410910606384,0.2598212659358978,0.2956109941005707,0.31837528944015503,0.3324747383594513,0.34473752975463867,0.35432928800582886,0.37885546684265137,0.3934200704097748,0.3800932765007019,0.3691765069961548,0.35953855514526367,0.33926284313201904,0.3730209171772003,0.3688947856426239,0.3906477689743042,0.3915136754512787,0.3618808388710022,0.3842604160308838,0.4149208068847656,0.32386714220046997,0.36124274134635925,0.36265936493873596,0.3279466927051544,0.355826735496521,0.3677922487258911,0.39434608817100525,0.39770999550819397,0.4030120074748993,0.4222084581851959,0.40404364466667175,0.39621880650520325,0.3429587781429291,0.33440449833869934,0.33408182859420776,0.3135528564453125,0.3352407217025757,0.2933498024940491,0.30902111530303955,0.2943391799926758,0.280557781457901,0.25611478090286255,0.26753562688827515,0.3105268180370331,0.31204578280448914,0.33580031991004944,0.3286437690258026,0.3145502507686615,0.3199266493320465,0.3241671621799469,0.3339862823486328,0.3379851281642914,0.34270191192626953,0.34586507081985474,0.34679123759269714,0.34781506657600403,0.34955745935440063,0.35223251581192017,0.35051611065864563,0.3371821641921997,0.3192555010318756,0.3264352083206177,0.34729766845703125,0.35119661688804626,0.35561126470565796,0.3601861894130707,0.36703649163246155,0.3700515627861023,0.3679214417934418,0.3569325804710388,0.34921520948410034,0.3515932857990265],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"shapes\":[{\"type\":\"line\",\"x0\":168,\"x1\":168,\"xref\":\"x\",\"y0\":0,\"y1\":1,\"yref\":\"y domain\"}],\"xaxis\":{\"title\":{\"text\":\"Time Samples\"}},\"yaxis\":{\"title\":{\"text\":\"Normalized Stock Opening Price\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d41c50ce-9f9f-4b09-9b3d-0111db762366');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "mu_no_volume, sigma_no_volume, label_no_volume =  get_pred_sigma_mu_labels(model)\n",
        "plot_test_output_data(label_no_volume.cpu().numpy(),mu_no_volume.cpu().numpy(), sigma_no_volume.cpu().numpy(), 11000 \n",
        "                      \n",
        "                      )\n",
        "# plot_test_output_data(label_no_volume.cpu().numpy(),samples_no_volume.cpu().numpy(), sigma_no_volume.cpu().numpy(), 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id1mRWuWNoRH",
        "outputId": "5e8a9af3-b982-4ab0-fa65-88c486cef0fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.7409, 0.7343, 0.7428,  ..., 1.1823, 1.2476, 1.2537], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(mu_no_volume)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "DL_project_basic_model_all_data_no_vol_with_context.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}